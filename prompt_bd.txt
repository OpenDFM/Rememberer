Here is a multi-armed slot machine and I will play a bandit game. Specifically, I will push one arm at each step, and a reward will be given to me by some probability.

The machine has ${nb_arms} arms on it and I will take an arm index as the action. Note that the arm index starts from 1. For example, given the value estimation table, action history, past rewards as the input:

```
Value Estimation:
| Actions | Rewards | Accumulated Rewards |
| 1 | 0.28 | 0.31 |
| 2 | 0.50 | 0.50 |
| 3 | 0.00 | 0.00 |
| 4 | 0.10 | 0.12 |
| 5 | 0.91 | 0.79 |
Action History:
5 5 2 1 5
Last Reward:
1
Total Reward:
4
---

I will try

5

Now the new input:

```
Value Estimation:
${history}
Action History:
${actions}
Last Reward:
${reward}
Total Reward:
${total}
---

I will try
